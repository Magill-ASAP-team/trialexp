{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Export a session as Spike2 data with Photometry data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.\n",
      "[NbConvertApp] Converting notebook d:\\OneDrive - Nexus365\\Private_Dropbox\\Projects\\trialexp\\notebooks\\noncanonical\\nb20230315_154600_Spike2Ppotometry.ipynb to python\n",
      "[NbConvertApp] Writing 12044 bytes to d:\\OneDrive - Nexus365\\Private_Dropbox\\Projects\\trialexp\\notebooks\\noncanonical\\nb20230315_154600_Spike2Ppotometry.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "nb_name = \"nb20230315_154600_Spike2Ppotometry.ipynb\" #TODO change this\n",
    "\n",
    "basename, ext = os.path.splitext(nb_name)\n",
    "input_path = os.path.join(os.getcwd(), nb_name)\n",
    "\n",
    "!jupyter nbconvert \"{input_path}\" --to=\"python\" --output=\"{basename}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# allow for automatic reloading of classes and function when updating the code\n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "# Import Session and Experiment class with helper functions\n",
    "from trialexp.process.data_import import *\n",
    "from trialexp.process.pyphotometry.photometry_functional import *\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trial_window = [-2000, 6000]  # in ms\n",
    "\n",
    "# time limit around trigger to perform an event\n",
    "# determine successful trials\n",
    "timelim = [0, 2000]  # in ms\n",
    "\n",
    "# Digital channel nb of the pyphotometry device\n",
    "# on which rsync signal is sent (from pycontrol device)\n",
    "rsync_chan = 2\n",
    "\n",
    "basefolder, _ = os.path.split(os.path.split(os.getcwd())[0])\n",
    "\n",
    "# These must be absolute paths\n",
    "# use this to use within package tasks files (in params)\n",
    "tasksfile = os.path.join(basefolder, 'params\\\\tasks_params.csv')\n",
    "# use this to put a local full path\n",
    "#tasksfile = -r'C:/.../tasks_params.csv'\n",
    "\n",
    "# photometry_dir = r'\\\\ettin\\Magill_Lab\\Julien\\Data\\head-fixed\\test_folder\\photometry'\n",
    "photometry_dir = r'\\\\ettin\\Magill_Lab\\Julien\\Data\\head-fixed\\pyphotometry\\data\\reaching_go_spout_bar_nov22'\n",
    "video_dir = r'\\\\ettin\\Magill_Lab\\Julien\\Data\\head-fixed\\videos'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = pd.read_csv(tasksfile, usecols=[1, 2, 3, 4], index_col=False)\n",
    "tasks\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an experiment object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder of a full experimental batch, all animals included\n",
    "\n",
    "# Enter absolute path like this\n",
    "# pycontrol_files_path = r'T:\\Data\\head-fixed\\test_folder\\pycontrol'\n",
    "\n",
    "# or this if you want to use data from the sample_data folder within the package\n",
    "#pycontrol_files_path = os.path.join(basefolder, 'sample_data/pycontrol')\n",
    "pycontrol_files_path = r'\\\\ettin\\Magill_Lab\\Julien\\Data\\head-fixed\\pycontrol\\reaching_go_spout_bar_nov22'\n",
    "\n",
    "# Load all raw text sessions in the indicated folder or a sessions.pkl file\n",
    "# if already existing in folder_path\n",
    "exp_cohort = Experiment(pycontrol_files_path, update=True)  # TODO\n",
    "\n",
    "# Only use if the Experiment cohort as been processed by trials before\n",
    "# TODO: assess whether this can be removed or not\n",
    "exp_cohort.by_trial = True\n",
    "\n",
    "\n",
    "smrx_folder_path = r'\\\\ettin\\Magill_Lab\\Julien\\Data\\head-fixed\\pycontrol\\reaching_go_spout_bar_nov22\\processed'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_cohort.match_sessions_to_files(photometry_dir, ext='ppd')\n",
    "exp_cohort.sync_photometry_files(2)\n",
    "exp_cohort.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "update_all_smrx = False\n",
    "\n",
    "ss = exp_cohort.sessions\n",
    "\n",
    "ss_ = [this_ss for this_ss in ss\n",
    "       if (this_ss.subject_ID in [58])\n",
    "       and (this_ss.task_name == 'reaching_go_spout_bar_mar23')\n",
    "       and (this_ss.datetime.date() >= datetime.date(2023, 3, 25))]\n",
    "ss_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_cohort.sessions = ss_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many combinations possible\n",
    "conditions_dict0 = {'trigger': 'hold_for_water', 'valid': True}\n",
    "\n",
    "\n",
    "# Aggregate all condition dictionaries in a list\n",
    "condition_list = [conditions_dict0]\n",
    "# Aliases for conditions\n",
    "cond_aliases = [\n",
    "    'any_trial',\n",
    "]\n",
    "\n",
    "# Groups as a list of lists\n",
    "groups = None\n",
    "\n",
    "# right_handed = [281]\n",
    "# groups = [[280, 282, 299, 300, 301],\\\n",
    "#     [284, 285, 296, 297, 306, 307]]\n",
    "# Window to exctract (in ms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_cohort.sessions[0].print_lines[0:30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ss in exp_cohort.sessions:\n",
    "    smrxname = re.sub('\\.txt', f'_{ss.task_name}.smrx', ss.file_name)\n",
    "    print(smrxname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_cohort.sessions[0].print_lines[0]\n",
    "\n",
    "a = re.sub('\\n', '', exp_cohort.sessions[0].print_lines[0])\n",
    "\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vars(exp_cohort.sessions[0].photometry_rsync)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "photometry_aligner = Rsync_aligner(exp_cohort.sessions[i].photometry_rsync.pulse_times_A, \n",
    "    exp_cohort.sessions[i].photometry_rsync.pulse_times_B,\n",
    "    chunk_size=5, plot=False, raise_exception=True)\n",
    "photometry_dict = import_ppd(exp_cohort.sessions[i].files['ppd'][0])\n",
    "photometry_times_pyc = photometry_aligner.B_to_A(photometry_dict['time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = list(exp_cohort.sessions[i].__dict__.keys())\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_list\n",
    "cond_aliases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy and modify `get_photometry_trials`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = exp_cohort.sessions[i]\n",
    "\n",
    "photometry_dict = import_ppd(session.files['ppd'][0])\n",
    "\n",
    "trig_on_ev = None\n",
    "last_before = None\n",
    "baseline_low_pass = 0.001, # var name changed from former high-pass,\n",
    "# was misleading on baseline computation\n",
    "# see https://github.com/juliencarponcy/trialexp/issues/8\n",
    "# first fix \n",
    "low_pass = 45\n",
    "median_filt = 3\n",
    "motion_corr = True\n",
    "df_over_f = True\n",
    "z_score = True\n",
    "downsampling_factor = 10\n",
    "return_full_session = True\n",
    "export_vars = ['analog_1_df_over_f', 'zscored_df_over_f']\n",
    "\n",
    "if low_pass:\n",
    "    # Filter signals with specified high and low pass frequencies (Hz).\n",
    "    b, a = get_filt_coefs(low_pass=low_pass, high_pass=None, sampling_rate=photometry_dict['sampling_rate'])\n",
    "    \n",
    "    if median_filt:\n",
    "        analog_1_medfilt = median_filtering(photometry_dict['analog_1'], medfilt_size = median_filt)\n",
    "        analog_2_medfilt = median_filtering(photometry_dict['analog_2'], medfilt_size = median_filt)\n",
    "        photometry_dict['analog_1_filt'] = filtfilt(b, a, analog_1_medfilt)\n",
    "        photometry_dict['analog_2_filt'] = filtfilt(b, a, analog_2_medfilt)\n",
    "\n",
    "    else:\n",
    "        photometry_dict['analog_1_filt'] = filtfilt(b, a, photometry_dict['analog_1'])\n",
    "        photometry_dict['analog_2_filt'] = filtfilt(b, a, photometry_dict['analog_2'])\n",
    "else:\n",
    "    if median_filt:\n",
    "        photometry_dict['analog_1_filt'] = median_filtering(photometry_dict['analog_1'], medfilt_size = median_filt)\n",
    "        photometry_dict['analog_2_filt'] = median_filtering(photometry_dict['analog_2'], medfilt_size = median_filt)  \n",
    "    else:\n",
    "        photometry_dict['analog_1_filt'] = photometry_dict['analog_2_filt'] = None\n",
    "# TODO: verify/improve/complement the implementation of the following:\n",
    "\n",
    "\n",
    "if motion_corr == True:\n",
    "\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(x=photometry_dict['analog_2_filt'], y=photometry_dict['analog_1_filt'])\n",
    "    photometry_dict['analog_1_est_motion'] = intercept + slope * photometry_dict['analog_2_filt']\n",
    "    photometry_dict['analog_1_corrected'] = photometry_dict['analog_1_filt'] - photometry_dict['analog_1_est_motion']\n",
    "    \n",
    "    if df_over_f == False:\n",
    "        export_vars.append('analog_1_corrected')\n",
    "        # signal = photometry_dict['analog_1_corrected']\n",
    "    elif df_over_f == True:\n",
    "        # fror \n",
    "        b,a = butter(2, baseline_low_pass, btype='low', fs=photometry_dict['sampling_rate'])\n",
    "        photometry_dict['analog_1_baseline_fluo'] = filtfilt(b,a, photometry_dict['analog_1_filt'], padtype='even')\n",
    "\n",
    "        # Now calculate the dF/F by dividing the motion corrected signal by the time varying baseline fluorescence.\n",
    "        photometry_dict['analog_1_df_over_f'] = photometry_dict['analog_1_corrected'] / photometry_dict['analog_1_baseline_fluo'] \n",
    "        export_vars.append('analog_1_df_over_f')\n",
    "        # signal = photometry_dict['analog_1_df_over_f']\n",
    "if z_score:\n",
    "    # z-score the signal\n",
    "    photometry_dict['zscored_df_over_f'] = zscore(photometry_dict['analog_1_df_over_f'])\n",
    "    export_vars.append('zscored_df_over_f')\n",
    "elif baseline_low_pass or low_pass:\n",
    "    # signal = photometry_dict['analog_1_filt']']\n",
    "    export_vars.append('analog_1_filt')\n",
    "\n",
    "    # control = photometry_dict['analog_2_filt']']\n",
    "else:\n",
    "    export_vars.append('analog_1')\n",
    "# signal = photometry_dict['analog_1']']\n",
    "\n",
    "# only keep unique items (keys for the photometry_dict)\n",
    "export_vars = list(set(export_vars))\n",
    "\n",
    "if downsampling_factor:\n",
    "    # downsample\n",
    "    for k in export_vars:\n",
    "        photometry_dict[k] = decimate(photometry_dict[k], downsampling_factor) \n",
    "    # adjust sampling rate accordingly (maybe unnecessary)\n",
    "    photometry_dict['sampling_rate'] = photometry_dict['sampling_rate'] / downsampling_factor\n",
    "\n",
    "# fs = photometry_dict['sampling_rate']\n",
    "\n",
    "df_meta_photo = pd.DataFrame(columns=['subject_ID', 'datetime', 'task_name', 'condition_ID', 'trial_nb'])\n",
    "\n",
    "# Prepare dictionary output with keys are variable names and values are columns index\n",
    "col_names_numpy = {var: var_idx for var_idx, var in enumerate(export_vars)}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_idx = np.zeros((1, 1))\n",
    "timestamps_pycontrol = np.zeros((1, 1))\n",
    "\n",
    "print(trials_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# assumes that sync between pycontrol and photometry has been performed in previous step\n",
    "timestamps_photometry = session.photometry_rsync.A_to_B(timestamps_pycontrol)\n",
    "\n",
    "photometry_idx = (timestamps_photometry / (1000/photometry_dict['sampling_rate'])).round().astype(int)\n",
    "\n",
    "# retain only trials with enough values left and right\n",
    "complete_mask = (photometry_idx + trial_window[0]/(1000/photometry_dict['sampling_rate']) >= 0) & (\n",
    "    photometry_idx + trial_window[1] < len(photometry_dict[export_vars[0]])) \n",
    "\n",
    "# complete_idx = np.where(complete_mask)\n",
    "# trials_idx = np.array(trials_idx)\n",
    "# photometry_idx = np.array(photometry_idx)\n",
    "\n",
    "trials_idx = trials_idx[complete_mask]           \n",
    "photometry_idx = photometry_idx[complete_mask]\n",
    "\n",
    "# if verbose:\n",
    "#     print(f'condition {condition_ID} trials: {len(trials_idx)}')\n",
    "\n",
    "if len(trials_idx) == 0:\n",
    "    print('nothing')\n",
    "\n",
    "# Construct ranges of idx to get chunks (trials) of photometry data with np.take method \n",
    "photometry_idx = [range(idx + int(trial_window[0]/(1000/photometry_dict['sampling_rate'])) ,\n",
    "    idx + int(trial_window[1]/(1000/photometry_dict['sampling_rate']))) for idx in photometry_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_array = np.ndarray((len(trials_idx), len(photometry_idx[0]),len(export_vars)))\n",
    "\n",
    "for var_idx, photo_var in enumerate(export_vars):\n",
    "    # print(f'condition {condition_ID} var: {var_idx} shape {np.take(photometry_dict[photo_var], photometry_idx).shape}')\n",
    "    photo_array[:,:,var_idx] = np.take(photometry_dict[photo_var], photometry_idx)\n",
    "\n",
    "\n",
    "df_meta_photo['trial_nb'] = trials_idx\n",
    "df_meta_photo['subject_ID'] = session.subject_ID\n",
    "df_meta_photo['datetime'] = session.datetime\n",
    "df_meta_photo['task_name'] = session.task_name\n",
    "# df_meta_photo['condition_ID'] = condition_ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'photo_array' in locals():\n",
    "            photo_array = photo_array.swapaxes(2,1)\n",
    "else:\n",
    "    # This occurs when no photometry data is recored at all for the session\n",
    "    # would occur anyway without the previous check, \n",
    "    # avoid it happening spontaneously on return.\n",
    "    # useless but could be use to convey extra information to calling method\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'No photometry data to collect for subject ID:{session.subject_ID}\\\n",
    "            \\nsession: {session.datetime}')\n",
    "\n",
    "    raise UnboundLocalError()\n",
    "\n",
    "    # Trying to implement empty arrays and dataframe when nothing to return\n",
    "    # df_meta_photo = pd.DataFrame(columns=['subject_ID', 'datetime', 'task_name', 'condition_ID', 'trial_nb'])\n",
    "    # ra\n",
    "    # photo_array = np.ndarray((len(trials_idx), len(photometry_idx),len(export_vars)))\n",
    "\n",
    "# df_meta_photo, col_names_numpy, photo_array, photometry_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = photometry_dict['analog_1']\n",
    "T = photometry_times_pyc \n",
    "\n",
    "nan_indices = np.argwhere(np.isnan(T))\n",
    "\n",
    "T_nonan = np.delete(T, nan_indices)\n",
    "Y_nonan = np.delete(Y, nan_indices)\n",
    "\n",
    "\n",
    "# Use Waveform\n",
    "# Need to use interp to accomodate data into Spike2 bins\n",
    "new_T = np.arange(0, 100, 0.01) #TODO\n",
    "new_Y = np.interp(new_T, T_nonan, Y_nonan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "int16_info = np.iinfo(np.int16)\n",
    "data = new_Y\n",
    "scale = ((np.max(data) - np.min(data))*6553.6) / float(int16_info.max - int16_info.min)\n",
    "offset = np.max(data) - float(int16_info.max) * scale/6553.6\n",
    "print(scale)\n",
    "print(offset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# session.plot_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.plot_session(keys=[], export_smrx = True, smrx_filename = 'temp.smrx', photometry_dict = photometry_dict)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_photometry_trials?\n",
    "\n",
    "`get_photometry_trials` > `get_trials_times_from_conditions`\n",
    "\n",
    "This function won't work for non-trial based analysis because it's dependent on `conditions_list`\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trialexp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
